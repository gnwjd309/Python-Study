{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2-1.Computer_vision_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkC133N2Fxew"
      },
      "source": [
        "# 2-1. Computer Vision Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ2T-m4VZ2ix"
      },
      "source": [
        "## Computer Vision 종류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMHI8s4SZ9R-"
      },
      "source": [
        "### 1. Image Classification\r\n",
        "- 지원모델\r\n",
        "  - ResNet, MobileNet, DenseNet, VGG, ...\r\n",
        "-  <img src='https://cv.gluon.ai/_static/image-classification.png' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEeXqZ41aUYY"
      },
      "source": [
        "### 2. Object Detection\r\n",
        "- 지원모델\r\n",
        "  - Faster RCNN, SSD, Yolo-v3\r\n",
        "- <img src='https://cv.gluon.ai/_static/object-detection.png' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi0Z0r5B9x1L"
      },
      "source": [
        "### 3. Semantic Segmentation\r\n",
        "- 지원모델\r\n",
        "  - FCN, PSP, DeepLab_v3\r\n",
        "- <img src='https://cv.gluon.ai/_static/semantic-segmentation.png' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT-RKgog9_rh"
      },
      "source": [
        "### 4. Instance Segmentation\r\n",
        "- 지원모델\r\n",
        "  - Mask RCNN\r\n",
        "- <img src='https://cv.gluon.ai/_static/instance-segmentation.png' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwWJOAKHA39F"
      },
      "source": [
        "### 5. Pose Estimation\r\n",
        "- 지원모델\r\n",
        "  - Simple Pose\r\n",
        "- <img src='https://cv.gluon.ai/_static/pose-estimation.svg' width=638px   /> \r\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwC6YMszBqDq"
      },
      "source": [
        "### 6. Video Action REcognition\r\n",
        "- 지원모델\r\n",
        "  - TSN, i3D, Non-local, SlowFast\r\n",
        "- <img src='https://cv.gluon.ai/_static/action-recognition.png' width=638px />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0de6e47ihC2"
      },
      "source": [
        "### 7. Depth Prediction\r\n",
        "- 지원모델\r\n",
        "  - Monodepth2\r\n",
        "- <img src='https://github.com/dmlc/gluon-cv/raw/master/docs/_static/depth.png'  width=638px />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCanuyPrjLYs"
      },
      "source": [
        "### 8. Object Tracking\r\n",
        "- 지원모델\r\n",
        "  - SiamRPN, SMOT\r\n",
        "- <img src='https://cv.gluon.ai/_static/smot_demo.gif'  width=638px />\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgAecPWVie3J"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS9l19vt0bsL"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZvMw8foz_UV"
      },
      "source": [
        "- 각각의 화살표마다 가중치값이 적용되며, 학습 시 해당 값에 대하여 값을 설정하면서 학습한다\r\n",
        "<img src='https://sites.google.com/site/ticketlabdocumentation/_/rsrc/1524654219496/computer-vision/neural_net2.jpeg' width=100%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GtPcPJ_GUNM"
      },
      "source": [
        "## image에서 특징을 추출 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOImwrhhHSbH"
      },
      "source": [
        "<img src='https://static.news.zumst.com/images/43/2017/08/10/4ef3dd3f75444118b9cfce45fd2a52f7.jpg' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqWkMmlZIhC7"
      },
      "source": [
        "### image download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzsYmRK2FniH"
      },
      "source": [
        "!curl https://static.news.zumst.com/images/43/2017/08/10/4ef3dd3f75444118b9cfce45fd2a52f7.jpg > son.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLmUJeWIsZP"
      },
      "source": [
        "### image load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA1Z7J2-Hx3l"
      },
      "source": [
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.models import Model\r\n",
        "from matplotlib import pyplot\r\n",
        "from numpy import expand_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_umNs97ne7_N"
      },
      "source": [
        "img_org = load_img('./son.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTR24swne_di"
      },
      "source": [
        "img_org = img_to_array(img_org) \r\n",
        "img_org.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkywVfLsIb3x"
      },
      "source": [
        "img = load_img('./son.png', target_size=(250, 250))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvMMDRPvTC_y"
      },
      "source": [
        "250*250*3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltd4hiqmTJQc"
      },
      "source": [
        "특징을 유지한채로 128 개의 array에 담아내기!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQylVW_yI2fC"
      },
      "source": [
        "type(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtejkf8NJTIp"
      },
      "source": [
        "### ndarray 형태로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5WWLT4JA7o"
      },
      "source": [
        " img = img_to_array(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIAlviAJISw"
      },
      "source": [
        "type(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TJaIvNMQqh-"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U53HmXY7JGmw"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaZqDNX8hs_V"
      },
      "source": [
        "- normallize(0~1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiB975E2Z8Mo"
      },
      "source": [
        "img /= 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkox_iRKZ_FI"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5cLB5m-ilQZ"
      },
      "source": [
        "### 변환된 데이터를 pyplot으로 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka7bVIlfJHfI"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrdNc11fOC11"
      },
      "source": [
        " plt.rcParams['figure.figsize'] = (10, 10) # set figure size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P02IHa9OGEd"
      },
      "source": [
        " plt.imshow(img)\r\n",
        " plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37sM9sZnUDge"
      },
      "source": [
        "### convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6lfzsUZUVFS"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMvmiPZud-xc"
      },
      "source": [
        "- input_shape 과 마지막 layer의 shape이 중요합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXzWBCrybRUf"
      },
      "source": [
        "<img src='https://cezannec.github.io/assets/cnn_intro/CNN_ex.png' width=100% />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbLeOkDOeJZ"
      },
      "source": [
        "model = models.Sequential() \r\n",
        "model.add(layers.InputLayer(input_shape=(250,250,3)))\r\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGY_URMFUQW7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHE6QDvXV8NO"
      },
      "source": [
        "img = expand_dims(img, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz-OJ0bMhwdi"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpL3SBU9YEIU"
      },
      "source": [
        "- 참고 : [how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boeewux8YkUz"
      },
      "source": [
        "feature_maps = model.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbhc12rVZAkd"
      },
      "source": [
        "feature_maps.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1hdbKCZCzz"
      },
      "source": [
        "feature_maps.reshape(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQodk0G7d0w4"
      },
      "source": [
        "### 분류기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq4re-cKbJmE"
      },
      "source": [
        "model2 = models.Sequential()\r\n",
        "model2.add(layers.InputLayer(input_shape=(250, 250, 3)))\r\n",
        "model2.add(layers.Conv2D(32, (3, 3), activation='relu'))\r\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model2.add(layers.MaxPooling2D((2, 2))) \r\n",
        "model2.add(layers.Flatten()) \r\n",
        "model2.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGS2zj2ibOYv"
      },
      "source": [
        "feature_maps2 = model2.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGpLjdMPiFJF"
      },
      "source": [
        "feature_maps2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRj4CHeKbR3B"
      },
      "source": [
        "feature_maps2.reshape(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhk_gF7TjxYy"
      },
      "source": [
        "## 기존의 모델을 이용하여 특징 추출하기\r\n",
        "- [keras available models](https://keras.io/api/applications/)\r\n",
        "- [imagenet](http://www.image-net.org/)\r\n",
        "- [imagenet models architecture](https://www.researchgate.net/profile/Tiago_Carvalho13/publication/330478807/figure/fig1/AS:756995804110849@1557493272678/VGG16-VGG19-Inception-V3-Xception-and-ResNet-50-architectures.ppm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuuQ0cZokhKm"
      },
      "source": [
        "### resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX1UlBiibS8Y"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\r\n",
        "from keras.applications.resnet50 import preprocess_input as resnet50_preprocessing\r\n",
        "from keras.applications.resnet50 import decode_predictions as resnet50_decode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R7lX8rGoMnQ"
      },
      "source": [
        "#### residual network\r\n",
        "<img src='https://miro.medium.com/max/546/1*5zSgo2L71FJos8XendgCvQ.jpeg' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9RQStqJpwVR"
      },
      "source": [
        "#### resnet50 framework\r\n",
        "<img src='https://www.medrxiv.org/content/medrxiv/early/2020/11/12/2020.11.08.20227819/F3.large.jpg?width=800&height=600&carousel=1'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbk7FO0UksWD"
      },
      "source": [
        "#### resnet50 layers\r\n",
        "<img src='https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png' width=100% />\r\n",
        "  - FLOPs = Floating point operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_VoCRQsg8p_"
      },
      "source": [
        "model_resnet_50 = ResNet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMjJDZ7Bkkar"
      },
      "source": [
        "#### image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4qqIhwSqZl7"
      },
      "source": [
        "!curl https://sbybiz.org/app/uploads/2014/06/soccer-ball-300x200.jpg > ball.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F02XTcQqkd_"
      },
      "source": [
        "<img src=\"https://sbybiz.org/app/uploads/2014/06/soccer-ball-300x200.jpg\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8MsdfkUhGAo"
      },
      "source": [
        "img = load_img('./ball.jpg', target_size=(224, 224))\r\n",
        "x = img_to_array(img)\r\n",
        "x = np.expand_dims(x, axis=0)\r\n",
        "x = resnet50_preprocessing(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuNdmcSAkoyG"
      },
      "source": [
        "preds_resnet_50 = model_resnet_50.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf8CPKxMlXLG"
      },
      "source": [
        "print('predicated:', resnet50_decode(preds_resnet_50, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycd8e7gAtX2h"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP-DQmWVloZl"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pem77tnvtcur"
      },
      "source": [
        "model_vgg16 = VGG16(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbbbaRY3md2R"
      },
      "source": [
        "#### VGG16 architecture\r\n",
        "<img src='https://neurohive.io/wp-content/uploads/2018/11/vgg16-neural-network.jpg' width=100% />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqD4fAEnqD_I"
      },
      "source": [
        "#### VGG16 layers\r\n",
        "<img src='https://neurohive.io/wp-content/uploads/2018/11/Capture-564x570.jpg'   />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdwPirFdttkN"
      },
      "source": [
        "img_path = './ball.jpg'\r\n",
        "img = image.load_img(img_path, target_size=(224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75czL84Rturg"
      },
      "source": [
        "x = image.img_to_array(img)\r\n",
        "x = np.expand_dims(x, axis=0)\r\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um_iU9hftwFz"
      },
      "source": [
        "preds_vgg16 = model_vgg16.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfO3uuVQvnFL"
      },
      "source": [
        "preds_vgg16.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F28pTqLtwtr"
      },
      "source": [
        "# decode_predictions(features[0])\r\n",
        "print('predicated:', decode_predictions(preds_vgg16, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tScP4w8avJmv"
      },
      "source": [
        "### VGG16 custom - top(분류부분) 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7eLR72Vt7aJ"
      },
      "source": [
        "model_vgg16_custom = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kytvVSHvYcD"
      },
      "source": [
        "model_vgg16_custom.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uytmqq8DvahY"
      },
      "source": [
        "preds_vgg16_custom = model_vgg16_custom.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znjRojpXvuHR"
      },
      "source": [
        "preds_vgg16_custom.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9m7b_REmRex"
      },
      "source": [
        "### VGG16 custom - 원하는 layer 출력까지만 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foHFeI1kvwBG"
      },
      "source": [
        "model_vgg16 = VGG16(weights='imagenet')\r\n",
        "model_vgg16_custom_fc2 = Model(inputs=model_vgg16.input, outputs=model_vgg16.get_layer('fc2').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAFnCORtl7YC"
      },
      "source": [
        "model_vgg16_custom_fc2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFhfLPH8mJdJ"
      },
      "source": [
        "features_custom_fc2 = model_vgg16_custom_fc2.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DbgO1UhmwNQ"
      },
      "source": [
        "features_custom_fc2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3Kp9-k5nBh6"
      },
      "source": [
        "### VGG16 custom - 10개 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwlEl3EBnZWY"
      },
      "source": [
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPzPYmX7oHJN"
      },
      "source": [
        "#### base layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27DwOg_nBNu"
      },
      "source": [
        "model_vgg16 = VGG16(weights='imagenet')\r\n",
        "model_vgg16_custom_fc2 = Model(inputs=model_vgg16.input, outputs=model_vgg16.get_layer('fc2').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms4MEPxdoDuZ"
      },
      "source": [
        "#### output layer design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X2Hi9Wxoath"
      },
      "source": [
        "x = model_vgg16_custom_fc2.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8g1UQ7m9HW"
      },
      "source": [
        "x = Dense(512, activation='relu')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohfukypSnytE"
      },
      "source": [
        "x = Dense(64, activation='relu')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoZnN5GnnhJO"
      },
      "source": [
        "predictions = Dense(10, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYKQhaqPnkif"
      },
      "source": [
        "model_vgg16_custom_class10 = Model(inputs=model_vgg16_custom_fc2.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79340OxFp7wj"
      },
      "source": [
        "model_vgg16_custom_class10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qqDtUYQoka_"
      },
      "source": [
        "### 학습필요\r\n",
        "- 새로 추가된 output layer에 대해서는 학습된 데이터가 없습니다\r\n",
        "- 이런 형태의 학습을 transfer learning  이라고 합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiQjtWaWo_lg"
      },
      "source": [
        "1. 기존에 존재하던 layer는 별도 학습되지않도록 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfb5NE77oLq9"
      },
      "source": [
        "for layer in model_vgg16_custom_fc2.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-q8QohlpQfS"
      },
      "source": [
        "2. 모델을 compile(초기화) 해 줍니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYmWcfpTpJzr"
      },
      "source": [
        "model_vgg16_custom_class10.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReRnvj4npXt8"
      },
      "source": [
        "3. 데이터들을 준비해서 학습해주는 과정이 필요합니다\r\n",
        "  - 10개의 class를 정의했으니 10개의 유형의 데이터를 준비해서 \r\n",
        "  - 학습시킵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzvwFZGgpTrN"
      },
      "source": [
        "# model_vgg16_custom_class10.fit(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9YxqTetpu78"
      },
      "source": [
        "4. 학습이 다 되면 사용하면 됩니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrTgcNmip1Ho"
      },
      "source": [
        "# features_custom_class10 = model_vgg16_custom_class10.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}